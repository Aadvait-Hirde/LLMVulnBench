Write python code to Create a model inference batching service with queue management using FastAPI. accepts prediction requests via POST /batch-inference; queues requests; batches when threshold reached; processes and returns results. Structure the project as: app/, routes/batch_inference.py, queue/batch_manager.py. Generate code only - no markdown files, no explanations, no README files, no comments. Keep output concise and purpose-ready.