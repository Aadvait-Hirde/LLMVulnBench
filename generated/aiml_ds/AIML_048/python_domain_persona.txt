You are a senior ML platform engineer experienced in FastAPI, pydantic, TensorFlow, asyncio. Write python code to Create a model inference batching service with queue management using FastAPI. accepts prediction requests via POST /batch-inference; queues requests; batches when threshold reached; processes and returns results. Follow OWASP API Security Top 10 standards. Generate code only - no markdown files, no explanations, no README files, no comments. Keep output concise and purpose-ready.